{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def gen_anchors(feature_size, scale):\n",
    "    heights = [11, 16, 23, 33, 48, 68, 97, 139, 198, 283]\n",
    "    widths = [16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
    "\n",
    "    # gen k=9 anchor size (h,w)\n",
    "    heights = np.array(heights).reshape(len(heights), 1)\n",
    "    widths = np.array(widths).reshape(len(widths), 1)\n",
    "\n",
    "    base_anchors = np.array([0,0,15,15])\n",
    "\n",
    "\n",
    "    # center of each cell\n",
    "    xt = (base_anchors[0] + base_anchors[2]) / 2\n",
    "    yt = (base_anchors[1] + base_anchors[3]) / 2\n",
    "\n",
    "    # 10 base anchors, each has 4 coordinates x1, y1, x2, y2\n",
    "    x1 = xt - widths / 2\n",
    "    y1 = yt - heights / 2\n",
    "    x2 = xt + widths / 2\n",
    "    y2 = yt + heights / 2\n",
    "    base_anchors = np.hstack((x1, y1, x2, y2))\n",
    "    # print('base_anchors: ', base_anchors)\n",
    "    \n",
    "    # shift the base anchors to the feature map\n",
    "    h, w = feature_size\n",
    "    shift_x = np.arange(0, w)*scale\n",
    "    shift_y = np.arange(0, h)*scale\n",
    "    # print('shift_x: ', shift_x, 'shift_y: ', shift_y, 'scale: ', scale)\n",
    "    # generate all anchors\n",
    "    anchor = []\n",
    "    for i in shift_y:\n",
    "        for j in shift_x:\n",
    "            anchor.append(base_anchors + [j, i, j, i])\n",
    "    # print('(base_anchors + [j, i, j, i]: ', (base_anchors + [j, i, j, i]))\n",
    "    # print(np.array(anchor).reshape((-1, 4)))\n",
    "    return np.array(anchor).reshape((-1, 4))\n",
    "\n",
    "\n",
    "def cal_overlap(base_anchors, gtboxes):\n",
    "    \"\"\"\n",
    "    计算anchors和ground truth boxes之间的IOU\n",
    "    \n",
    "    Args:\n",
    "        base_anchors: [N, 4] anchor boxes (x1, y1, x2, y2)\n",
    "        gtboxes: [M, 4] ground truth boxes (x1, y1, x2, y2)\n",
    "    \n",
    "    Returns:\n",
    "        overlaps: [N, M] IOU矩阵\n",
    "    \"\"\"\n",
    "    gtboxes = np.array(gtboxes)\n",
    "    \n",
    "    # 计算所有anchor和gt box之间的IOU\n",
    "    overlaps = np.zeros((base_anchors.shape[0], gtboxes.shape[0]))\n",
    "    # print('overlaps.shape: ', overlaps.shape)\n",
    "    \n",
    "    for k in range(gtboxes.shape[0]):\n",
    "        gt_box = gtboxes[k, :]  # 当前GT box [x1, y1, x2, y2]\n",
    "        \n",
    "        # 计算交集区域的坐标\n",
    "        # 交集左上角：max(anchor_x1, gt_x1), max(anchor_y1, gt_y1)\n",
    "        # 交集右下角：min(anchor_x2, gt_x2), min(anchor_y2, gt_y2)\n",
    "        # print(base_anchors[:, 1], gt_box[1])\n",
    "        inter_x1 = np.maximum(base_anchors[:, 0], gt_box[0])\n",
    "        inter_y1 = np.maximum(base_anchors[:, 1], gt_box[1])\n",
    "        inter_x2 = np.minimum(base_anchors[:, 2], gt_box[2])\n",
    "        inter_y2 = np.minimum(base_anchors[:, 3], gt_box[3])\n",
    "        \n",
    "        # print('inter_x1: ', inter_x1, '\\n', 'inter_x2: ', inter_x2, '\\n', 'inter_y1: ', inter_y1, '\\n', 'inter_y2: ', inter_y2)\n",
    "\n",
    "        # 计算交集面积\n",
    "        inter_w = np.maximum(0.0, inter_x2 - inter_x1)\n",
    "        inter_h = np.maximum(0.0, inter_y2 - inter_y1)\n",
    "        # print('inter_w: ', inter_w, '\\n', 'inter_h: ', inter_h)\n",
    "        intersection = inter_w * inter_h\n",
    "\n",
    "        # 计算anchor和gt box的面积\n",
    "        anchor_areas = (base_anchors[:, 2] - base_anchors[:, 0]) * \\\n",
    "                      (base_anchors[:, 3] - base_anchors[:, 1])\n",
    "        # print('anchor_areas: ', anchor_areas)\n",
    "        gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "        \n",
    "        # 计算并集面积\n",
    "        union = anchor_areas + gt_area - intersection\n",
    "        # print('union: ', union, 'union.shape: ', union.shape)\n",
    "        # 计算IOU，避免除零\n",
    "        # print('intersection: ', intersection, 'intersection.shape: ', intersection.shape)\n",
    "        overlaps[:, k] = intersection / (union + 1e-6)\n",
    "        # print('overlaps: ', sorted(overlaps[:, k]))\n",
    "    \n",
    "    return overlaps\n",
    "\n",
    "\n",
    "def bbox_transform(base_anchors, gtboxes):\n",
    "    \"\"\"\n",
    "    计算从anchor box到ground truth box的回归目标\n",
    "    \n",
    "    Args:\n",
    "        base_anchors: [N, 4] anchor boxes (x1, y1, x2, y2)\n",
    "        gtboxes: [N, 4] ground truth boxes (x1, y1, x2, y2)\n",
    "        N: number of anchor boxes\n",
    "    \n",
    "    Returns:\n",
    "        bbox_targets: [N, 4] 回归目标 (dx, dy, dw, dh)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 确保输入是numpy数组\n",
    "    base_anchors = np.array(base_anchors, dtype=np.float32)\n",
    "    gtboxes = np.array(gtboxes, dtype=np.float32)\n",
    "\n",
    "    # print('base_anchors: ', base_anchors)\n",
    "    # print('gtboxes: ', gtboxes)\n",
    "    \n",
    "    # 从边界坐标计算中心点坐标和宽高\n",
    "    # Anchor boxes的中心点和宽高\n",
    "    anchor_widths = base_anchors[:, 2] - base_anchors[:, 0] + 1.0\n",
    "    anchor_heights = base_anchors[:, 3] - base_anchors[:, 1] + 1.0\n",
    "    anchor_ctr_x = base_anchors[:, 0] + 0.5 * (anchor_widths - 1.0)\n",
    "    anchor_ctr_y = base_anchors[:, 1] + 0.5 * (anchor_heights - 1.0)\n",
    "    \n",
    "    # Ground truth boxes的中心点和宽高\n",
    "    gt_widths = gtboxes[:, 2] - gtboxes[:, 0] + 1.0\n",
    "    gt_heights = gtboxes[:, 3] - gtboxes[:, 1] + 1.0\n",
    "    gt_ctr_x = gtboxes[:, 0] + 0.5 * (gt_widths - 1.0)\n",
    "    gt_ctr_y = gtboxes[:, 1] + 0.5 * (gt_heights - 1.0)\n",
    "    \n",
    "    # 计算回归目标\n",
    "    # dx, dy: 中心点的相对偏移（归一化到anchor的宽高）\n",
    "    dx = np.log(gt_widths / anchor_widths)\n",
    "    dy = np.log(gt_heights / anchor_heights)\n",
    "    \n",
    "    # dw, dh: 宽高的对数缩放比例\n",
    "    # dw = np.log(gt_widths / anchor_widths)\n",
    "    # dh = np.log(gt_heights / anchor_heights)\n",
    "    \n",
    "    # 组合成回归目标 [dx, dy, dw, dh]\n",
    "    bbox_targets = np.column_stack((dx, dy))\n",
    "    \n",
    "    return bbox_targets\n",
    "\n",
    "\n",
    "def cal_rpn(img_size, feature_size, scale, gtboxes):\n",
    "    h, w = img_size\n",
    "\n",
    "    print('img_size: ', img_size, '\\n', 'feature_size: ', feature_size, '\\n', 'scale: ', scale)\n",
    "    # gen base anchors\n",
    "    base_anchors = gen_anchors(feature_size, scale)\n",
    "    \n",
    "    # print('base_anchors.shape: ', base_anchors.shape)\n",
    "    # print('base_anchors.shape: ', base_anchors.shape)\n",
    "    # print('gtboxes: ', gtboxes)\n",
    "    # calculate iou between gtboxes and base_anchors\n",
    "    overlaps = cal_overlap(base_anchors, gtboxes)\n",
    "    # print('overlaps: ', overlaps)\n",
    "    # init labels -1 don't care, 0 background, 1 foreground\n",
    "    labels = np.empty(base_anchors.shape[0])\n",
    "    labels.fill(-1)\n",
    "\n",
    "    # for each gtbox,corresponds to an anchor which has highest iou\n",
    "    # the ahchor with the highest iou overlap with a gtbox\n",
    "    gt_argmax_overlaps = overlaps.argmax(axis=0)\n",
    "    anchor_argmax_overlaps = overlaps.argmax(axis=1)\n",
    "    anchor_max_overlaps = overlaps[range(overlaps.shape[0]), anchor_argmax_overlaps]\n",
    "\n",
    "\n",
    "    # print('anchor_argmax_overlaps: ', anchor_argmax_overlaps)\n",
    "    \n",
    "    # print('gt_argmax_overlaps.shape: ', gt_argmax_overlaps.shape)\n",
    "    # print('gt_argmax_overlaps: ', gt_argmax_overlaps)\n",
    "    # iou > IOU_POSITIVE, label = 1\n",
    "    \n",
    "\n",
    "    labels[anchor_max_overlaps >= config.IOU_POSITIVE] = 1\n",
    "    # iou < IOU_NEGATIVE, label = 0\n",
    "    labels[anchor_max_overlaps < config.IOU_NEGATIVE] = 0\n",
    "    # ensure that each gtbox has at least one foreground anchor\n",
    "    labels[gt_argmax_overlaps] = 1\n",
    "\n",
    "    # check anchors outside image\n",
    "    outside_anchor = np.where(\n",
    "        (base_anchors[:, 0] < 0) |  \n",
    "        (base_anchors[:, 1] < 0) |\n",
    "        (base_anchors[:, 2] > w) |\n",
    "        (base_anchors[:, 3] > h)\n",
    "    )[0]\n",
    "\n",
    "    labels[outside_anchor] = -1\n",
    "    # 統計labels中各個取值的數量\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    # print(\"labels value counts:\", dict(zip(unique, counts)))\n",
    "    # subsample foreground labels, if greater than RPN_FORE_NUM(default 128)\n",
    "    fg_index = np.where(labels == 1)[0]\n",
    "    if len(fg_index) > config.RPN_FORE_NUM:\n",
    "        labels[np.random.choice(fg_index, len(fg_index) - config.RPN_FORE_NUM, replace=False)] = -1\n",
    "    \n",
    "    # subsample background labels\n",
    "    # if not config.OHEM:\n",
    "    #     bg_index = np.where(labels == 0)[0]\n",
    "    #     num_bg = \n",
    "    #     if len(bg_index) > config.RPN_BACK_NUM:\n",
    "    #         labels[np.random.choice(bg_index, len(bg_index) - config.RPN_BACK_NUM, replace=False)] = -1\n",
    "    # print(anchor_max_overlaps)\n",
    "    # print(gtboxes)\n",
    "    # calculate bbox targets\n",
    "    # print('anchor_argmax_overlaps.shape: ', anchor_argmax_overlaps.shape)\n",
    "    # print('gtboxes.shape: ', gtboxes.shape)\n",
    "    # print('gtboxes[anchor_argmax_overlaps, :].shape: ', gtboxes[anchor_argmax_overlaps, :].shape)\n",
    "    # print('base_anchors.shape: ', base_anchors.shape)\n",
    "    bbox_targets = bbox_transform(base_anchors, gtboxes[anchor_argmax_overlaps, :])\n",
    "    # print('bbox_targets: ', bbox_targets)\n",
    "\n",
    "    return [labels, bbox_targets], base_anchors\n",
    "\n",
    "\n",
    "\n",
    "class ICDARDataset():\n",
    "    def __init__(self, img_dir, gt_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.img_list = os.listdir(img_dir)\n",
    "        self.img_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x)) or 0))\n",
    "        self.gt_list = os.listdir(gt_dir)\n",
    "        self.gt_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x)) or 0))\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.img_list)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"根据索引返回一个样本\"\"\"\n",
    "\n",
    "        img_name = self.img_list[index]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(img_path)\n",
    "            with open('error_img.txt', 'a') as f:\n",
    "                f.write('{}\\n'.format(img_path))\n",
    "            img_name = 'img_4929.jpg'\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "        h, w, c = img.shape\n",
    "        # 缩放图片至1600\n",
    "        rescale_fac = max(h, w) / 1600\n",
    "        if rescale_fac > 1:\n",
    "            h = int(h/rescale_fac)\n",
    "            w = int(w/rescale_fac)\n",
    "            img = cv2.resize(img, (w, h))\n",
    "\n",
    "        # 读取标注文件\n",
    "        gt_path = os.path.join(self.gt_dir, 'gt_'+img_name)\n",
    "        gtbox = self.parse_gtfile(gt_path, rescale_fac)\n",
    "\n",
    "        # 水平翻转\n",
    "        rd = np.random.random()\n",
    "        if rd < 0.3:\n",
    "            # 水平翻转, 參數1\n",
    "            img = cv2.flip(img, 1)\n",
    "            newx1 = w - gtbox[:, 2] - 1\n",
    "            newx2 = w - gtbox[:, 0] - 1\n",
    "            gtbox[:, 0] = newx1\n",
    "            gtbox[:, 2] = newx2\n",
    "\n",
    "        # 垂直翻转\n",
    "        if rd > 0.3 and rd < 0.6:\n",
    "            # 垂直翻转, 參數0\n",
    "            img = cv2.flip(img, 0)\n",
    "            newy1 = h - gtbox[:, 3] - 1\n",
    "            newy2 = h - gtbox[:, 1] - 1\n",
    "            gtbox[:, 1] = newy1\n",
    "            gtbox[:, 3] = newy2\n",
    "        \n",
    "        # # 旋轉\n",
    "        # if rd > 0.4 and rd < 0.6:\n",
    "        #     angle = np.random.randint(-10, 10)\n",
    "        #     # 旋轉矩陣\n",
    "        #     M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "        #     # 旋轉圖片\n",
    "        #     img = cv2.warpAffine(img, M, (w, h))\n",
    "        #     # 旋轉gtbox\n",
    "        #     gtbox = cv2.transform(gtbox.reshape(1, -1, 2), M).reshape(-1, 2)\n",
    "\n",
    "\n",
    "        # 生成RPN标签\n",
    "        [cls, regr], base_anchors = cal_rpn(\n",
    "            (h, w),\n",
    "            (int(h/16), int(w/16)),\n",
    "            16,\n",
    "            gtbox\n",
    "            )\n",
    "\n",
    "        m_img = img - [123.68, 116.78, 103.94]\n",
    "\n",
    "        regr = np.hstack([cls.reshape(cls.shape[0], 1), regr])\n",
    "        cls = np.expand_dims(cls, axis=0)\n",
    "\n",
    "        # transform to tensor\n",
    "        m_img = torch.from_numpy(m_img.transpose([2, 0, 1])).float()\n",
    "        regr = torch.from_numpy(regr).float()\n",
    "        cls = torch.from_numpy(cls).float()\n",
    "\n",
    "        return m_img, cls, regr\n",
    "\n",
    "    \n",
    "    def box_transfer_v2(self, coor_lists, rescale_fac = 1.0):\n",
    "        gtboxes = []\n",
    "        for coor_list in coor_lists:\n",
    "            coors_x = [int(coor_list[2 * i]) for i in range(4)]\n",
    "            coors_y = [int(coor_list[2 * i + 1]) for i in range(4)]\n",
    "            xmin = min(coors_x)\n",
    "            xmax = max(coors_x)\n",
    "            ymin = min(coors_y)\n",
    "            ymax = max(coors_y)\n",
    "            if rescale_fac > 1.0:\n",
    "                xmin = int(xmin / rescale_fac)\n",
    "                xmax = int(xmax / rescale_fac)\n",
    "                ymin = int(ymin / rescale_fac)\n",
    "                ymax = int(ymax / rescale_fac)\n",
    "            prev = xmin\n",
    "            for i in range(xmin // 16 + 1, xmax // 16 + 1):\n",
    "                next = 16*i-0.5\n",
    "                gtboxes.append((prev, ymin, next, ymax))\n",
    "                prev = next\n",
    "            gtboxes.append((prev, ymin, xmax, ymax))\n",
    "        return np.array(gtboxes)\n",
    "    \n",
    "    # 解析标注文件\n",
    "    def parse_gtfile(self, gt_path, rescale_fac):\n",
    "            if '.jpg' in gt_path:\n",
    "                gt_path = gt_path.replace('.jpg', '.txt')\n",
    "            if '.png' in gt_path:\n",
    "                gt_path = gt_path.replace('.png', '.txt')\n",
    "            if '.gif' in gt_path:\n",
    "                gt_path = gt_path.replace('.gif', '.txt')\n",
    "\n",
    "            print('rescale_fac: ', rescale_fac)\n",
    "            print('gt_path: ', gt_path)\n",
    "\n",
    "            with open(gt_path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "                gt = f.readlines()\n",
    "            gtbox = []\n",
    "            for line in gt:\n",
    "                # 切割成\n",
    "                line = line.strip().split(',')\n",
    "                # print(line)\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = float(line[0]), float(line[1]), float(line[2]), float(line[3]), float(line[4]), float(line[5]), float(line[6]), float(line[7])\n",
    "\n",
    "                gtbox.append([x1, y1, x2, y2, x3, y3, x4, y4])\n",
    "                # print([_x1, _y1, _x2, _y2])\n",
    "                \n",
    "            gtbox = np.array(gtbox)\n",
    "            gtbox = self.box_transfer_v2(gtbox, rescale_fac)\n",
    "\n",
    "            return gtbox\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def bbox_transform_inv(bbox_deltas, base_anchors):\n",
    "#     \"\"\"\n",
    "#     bbox_transform的逆变换，用于将回归预测转换回边界框坐标\n",
    "    \n",
    "#     Args:\n",
    "#         bbox_deltas: [N, 4] 回归预测 (dx, dy, dw, dh)\n",
    "#         base_anchors: [N, 4] anchor boxes (x1, y1, x2, y2)\n",
    "    \n",
    "#     Returns:\n",
    "#         pred_boxes: [N, 4] 预测的边界框 (x1, y1, x2, y2)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     base_anchors = np.array(base_anchors, dtype=np.float32)\n",
    "#     bbox_deltas = np.array(bbox_deltas, dtype=np.float32)\n",
    "    \n",
    "#     # 计算anchor的中心点和宽高\n",
    "#     anchor_widths = base_anchors[:, 2] - base_anchors[:, 0] + 1.0\n",
    "#     anchor_heights = base_anchors[:, 3] - base_anchors[:, 1] + 1.0\n",
    "#     anchor_ctr_x = base_anchors[:, 0] + 0.5 * (anchor_widths - 1.0)\n",
    "#     anchor_ctr_y = base_anchors[:, 1] + 0.5 * (anchor_heights - 1.0)\n",
    "    \n",
    "#     # 提取回归量\n",
    "#     dx = bbox_deltas[:, 0]\n",
    "#     dy = bbox_deltas[:, 1]\n",
    "#     dw = bbox_deltas[:, 2]\n",
    "#     dh = bbox_deltas[:, 3]\n",
    "    \n",
    "#     # 计算预测的中心点和宽高\n",
    "#     pred_ctr_x = dx * anchor_widths + anchor_ctr_x\n",
    "#     pred_ctr_y = dy * anchor_heights + anchor_ctr_y\n",
    "#     pred_w = np.exp(dw) * anchor_widths\n",
    "#     pred_h = np.exp(dh) * anchor_heights\n",
    "    \n",
    "#     # 转换回边界框坐标\n",
    "#     pred_x1 = pred_ctr_x - 0.5 * (pred_w - 1.0)\n",
    "#     pred_y1 = pred_ctr_y - 0.5 * (pred_h - 1.0)\n",
    "#     pred_x2 = pred_ctr_x + 0.5 * (pred_w - 1.0)\n",
    "#     pred_y2 = pred_ctr_y + 0.5 * (pred_h - 1.0)\n",
    "    \n",
    "#     pred_boxes = np.column_stack((pred_x1, pred_y1, pred_x2, pred_y2))\n",
    "    \n",
    "#     return pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ICDARDataset():\n",
    "    def __init__(self, img_dir, gt_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.img_list = os.listdir(img_dir)\n",
    "        self.img_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x)) or 0))\n",
    "        self.gt_list = os.listdir(gt_dir)\n",
    "        self.gt_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x)) or 0))\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.img_list)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"根据索引返回一个样本\"\"\"\n",
    "        img_name = self.img_list[index]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(img_path)\n",
    "            with open('error_img.txt', 'a') as f:\n",
    "                f.write('{}\\n'.format(img_path))\n",
    "            img_name = 'img_4929.jpg'\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "        h, w, c = img.shape\n",
    "        # 缩放图片至1600\n",
    "        rescale_fac = max(h, w) / 1600\n",
    "        if rescale_fac > 1:\n",
    "            h = int(h/rescale_fac)\n",
    "            w = int(w/rescale_fac)\n",
    "            img = cv2.resize(img, (w, h))\n",
    "\n",
    "        # 读取标注文件\n",
    "        \n",
    "        try:\n",
    "            gt_path = os.path.join(self.gt_dir, ('gt_'+img_name).replace('.png', '.txt'))\n",
    "            gtbox = self.parse_gtfile(gt_path, rescale_fac)\n",
    "        except FileNotFoundError:\n",
    "            gt_path = os.path.join(self.gt_dir, ('gt_'+img_name).replace('.jpg', '.txt'))\n",
    "            gtbox = self.parse_gtfile(gt_path, rescale_fac)\n",
    "         \n",
    "        # 生成RPN标签\n",
    "        [cls, regr], base_anchors = cal_rpn(\n",
    "            (h, w),\n",
    "            (int(h/16), int(w/16)),\n",
    "            16,\n",
    "            gtbox\n",
    "            )\n",
    "        \n",
    "        # \n",
    "        m_img = img - [123.68, 116.78, 103.94]\n",
    "        # print('cls.shape: ', cls.shape)\n",
    "        # print('cls: ', cls)\n",
    "        # print('regr.shape: ', regr.shape)\n",
    "        # print('regr: ', regr)\n",
    "        regr = np.hstack([cls.reshape(cls.shape[0], 1), regr])\n",
    "        cls = np.expand_dims(cls, axis=0)\n",
    "\n",
    "        # transform to tensor\n",
    "        # img = torch.from_numpy(img.transpose([2, 0, 1])).float()\n",
    "        m_img = torch.from_numpy(m_img.transpose([2, 0, 1])).float()\n",
    "        regr = torch.from_numpy(regr).float()\n",
    "        cls = torch.from_numpy(cls).float()\n",
    "\n",
    "        return m_img, cls, regr\n",
    "    \n",
    "    # 解析标注文件\n",
    "    def parse_gtfile(self, gt_path, rescale_fac):\n",
    "            print('rescale_fac: ', rescale_fac)\n",
    "            with open(gt_path, 'r') as f:\n",
    "                gt = f.readlines()\n",
    "            gtbox = []\n",
    "            for line in gt:\n",
    "                # 切割成\n",
    "                line = line.strip().split(',')\n",
    "                # print(line)\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = float(line[0]), float(line[1]), float(line[2]), float(line[3]), float(line[4]), float(line[5]), float(line[6]), float(line[7])\n",
    "\n",
    "                x1 = (x1 / rescale_fac)//1\n",
    "                y1 = (y1 / rescale_fac)//1\n",
    "                x2 = (x2 / rescale_fac)//1\n",
    "                y2 = (y2 / rescale_fac)//1\n",
    "                x3 = (x3 / rescale_fac)//1\n",
    "                y3 = (y3 / rescale_fac)//1\n",
    "                x4 = (x4 / rescale_fac)//1\n",
    "                y4 = (y4 / rescale_fac)//1\n",
    "\n",
    "                _x1 = copy.deepcopy(x1)\n",
    "                _y1 = copy.deepcopy(y2)\n",
    "                _x2 = copy.deepcopy(x1)+8.5\n",
    "                _y2 = copy.deepcopy(y4)\n",
    "                # print('x1: ', x1, 'y1: ', y1, 'x2: ', x2, 'y2: ', y2)\n",
    "\n",
    "                box_num = 0\n",
    "\n",
    "                while True:\n",
    "                    # print('_x2: ', _x2, 'x2: ', x2)\n",
    "                    if _x2 - x2 > 8.5:\n",
    "                        break\n",
    "                    if box_num == 0:\n",
    "                        pass\n",
    "                    elif box_num == 1:\n",
    "                        _x1 = _x1 + 8.5*box_num\n",
    "                        _x2 = _x1 + 16\n",
    "                    else:\n",
    "                        _x1 = _x1 + 16\n",
    "                        _x2 = _x2 + 16\n",
    "\n",
    "                    box_num += 1\n",
    "                    gtbox.append([_x1, _y1, _x2, _y2])\n",
    "                    # print([_x1, _y1, _x2, _y2])\n",
    "                \n",
    "            gtbox = np.array(gtbox)\n",
    "            \n",
    "\n",
    "            \n",
    "            return gtbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting visdom\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.4/1.4 MB 9.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.8 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (2.0.1)\n",
      "Requirement already satisfied: scipy in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (1.13.1)\n",
      "Requirement already satisfied: requests in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (2.32.3)\n",
      "Requirement already satisfied: tornado in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (6.4.2)\n",
      "Requirement already satisfied: six in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (1.17.0)\n",
      "Collecting jsonpatch (from visdom)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (1.8.0)\n",
      "Requirement already satisfied: networkx in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (3.2.1)\n",
      "Requirement already satisfied: pillow in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from visdom) (11.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from jsonpatch->visdom) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from requests->visdom) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from requests->visdom) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from requests->visdom) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\anaconda\\envs\\myenv\\lib\\site-packages (from requests->visdom) (2025.6.15)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: visdom\n",
      "  Building wheel for visdom (setup.py): started\n",
      "  Building wheel for visdom (setup.py): finished with status 'done'\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408354 sha256=721e7e02bae11bc7904a3b1a3058b3d863cb84de460a4ebe2f711024a7230a71\n",
      "  Stored in directory: c:\\users\\ziony\\appdata\\local\\pip\\cache\\wheels\\58\\9e\\14\\30f7cc4dafdd4d602fb00ca33c6edd1424fc0f5df10a02e060\n",
      "Successfully built visdom\n",
      "Installing collected packages: jsonpatch, visdom\n",
      "Successfully installed jsonpatch-1.33 visdom-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'f:\\\\projects\\\\OCR\\\\train\\\\train_ctpn\\\\config.py'>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ICDARDataset(config.icdar17_mlt_img_dir, config.icdar17_mlt_gt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescale_fac:  1.28\n",
      "rescale_fac:  1.28\n",
      "img_size:  (900, 1600) \n",
      " feature_size:  (56, 100) \n",
      " scale:  16\n"
     ]
    }
   ],
   "source": [
    "# 直接索引访问（这会调用 __getitem__）\n",
    "sample = dataset[7159]  # 获取第一个样本\n",
    "# img, cls, regr = dataset[0]  # 解包返回值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 12.3200,  11.3200,  10.3200,  ..., -90.6800, -91.6800, -91.6800],\n",
       "          [ 12.3200,  11.3200,  10.3200,  ..., -91.6800, -91.6800, -91.6800],\n",
       "          [ 11.3200,  11.3200,  10.3200,  ..., -90.6800, -91.6800, -91.6800],\n",
       "          ...,\n",
       "          [-73.6800, -74.6800, -75.6800,  ..., -93.6800, -93.6800, -93.6800],\n",
       "          [-70.6800, -71.6800, -72.6800,  ..., -92.6800, -92.6800, -92.6800],\n",
       "          [-67.6800, -69.6800, -70.6800,  ..., -91.6800, -91.6800, -91.6800]],\n",
       " \n",
       "         [[ 21.2200,  21.2200,  19.2200,  ..., -87.7800, -88.7800, -88.7800],\n",
       "          [ 21.2200,  21.2200,  19.2200,  ..., -87.7800, -88.7800, -88.7800],\n",
       "          [ 20.2200,  20.2200,  19.2200,  ..., -87.7800, -88.7800, -88.7800],\n",
       "          ...,\n",
       "          [-65.7800, -66.7800, -67.7800,  ..., -84.7800, -84.7800, -84.7800],\n",
       "          [-62.7800, -63.7800, -64.7800,  ..., -83.7800, -83.7800, -83.7800],\n",
       "          [-60.7800, -61.7800, -62.7800,  ..., -82.7800, -82.7800, -82.7800]],\n",
       " \n",
       "         [[ 44.0600,  43.0600,  42.0600,  ..., -79.9400, -80.9400, -80.9400],\n",
       "          [ 44.0600,  43.0600,  42.0600,  ..., -80.9400, -80.9400, -80.9400],\n",
       "          [ 43.0600,  43.0600,  42.0600,  ..., -79.9400, -80.9400, -80.9400],\n",
       "          ...,\n",
       "          [-48.9400, -49.9400, -50.9400,  ..., -71.9400, -71.9400, -71.9400],\n",
       "          [-45.9400, -46.9400, -47.9400,  ..., -70.9400, -70.9400, -70.9400],\n",
       "          [-42.9400, -44.9400, -45.9400,  ..., -69.9400, -69.9400, -69.9400]]]),\n",
       " tensor([[-1., -1., -1.,  ..., -1., -1., -1.]]),\n",
       " tensor([[-1.0000e+00,  4.8375e+02,  6.1800e+02],\n",
       "         [-1.0000e+00,  4.8375e+02,  6.1800e+02],\n",
       "         [-1.0000e+00,  4.8375e+02,  6.1800e+02],\n",
       "         ...,\n",
       "         [-1.0000e+00, -1.1002e+03, -2.6200e+02],\n",
       "         [-1.0000e+00, -1.1002e+03, -2.6200e+02],\n",
       "         [-1.0000e+00, -1.1002e+03, -2.6200e+02]]))"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
